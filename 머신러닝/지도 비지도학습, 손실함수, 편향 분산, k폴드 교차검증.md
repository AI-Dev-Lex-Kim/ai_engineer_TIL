### 지도 학습과 비지도 학습의 차이는 무엇인가요?

지도학습이란 모델에 목표로 해야하는 데이터를 준다.

그리고 그 데이터에 맞게 모델이 알고리즘을 거쳐 속성을 통해 예측이 맞도록 학습시켜준다.

<br>

일단 비지도학습은 데이터를 바탕으로 학습을 한다.

이 데이터들은 정답이 없는 데이터들이다.

각 여러 속성들의 값이 포함된 데이터들이 모여 있는 데이터 셋이다.

여기서 비지도학습은 정답이 없기 때문에, 각 속성에 따라 비슷한 데이터들끼리 묶어주는 작업을 한다.

데이터를 묶을 때는 각 데이터들이 얼마나 비슷한지 평가한다.

이렇게 데이터들 간의 가장 비슷한 데이터들끼리 그룹을 만든다.

그룹화가 잘 되었는지 확인하기 위해**점수**를 낸다.

이 과정을 통해, 모델은 데이터를 반복적으로 그룹화하고, 점수에 따라그룹의 품질을 평가하여반복 학습을 통해 최적의 그룹화를 찾아낸다.

<br>

### 손실 함수(loss function)란 무엇이며, 왜 중요한가요?

모델이 데이터를 학습하는 과정에서 예측된 결과 값이 나온다.
그 예측된 결과와 실제 값 사이에는 오차가 발생한다.
이 오차를 줄이기 위해 오차의 정도를 수치로 표현해주는 함수가 바로 손실 함수(loss function)이다.
손실 함수는 모델이 예측한 값과 실제 값 사이의 차이를 계산하고, 이 값을 최소화하려고 한다.
즉, 모델은 손실 함수를 통해 예측을 더 정확하게 만들기 위해 오차를 줄여가는 방향으로 학습을 진행한다.

<br>

### 모델 학습 시 발생할 수 있는 편향과 분산에 대해 설명하고, 두 개념의 관계에 대해 설명해 주세요.

### 1. **편향(bias)**

- **편향이 크다**: 모델이 너무 간단해서 훈련 데이터의 패턴을 제대로 파악하지 못하는 경우입니다. 이때 모델은 **과소적합(underfitting)** 상태에 빠진다. 즉, 훈련 데이터에서 예측이 잘 맞지 않게 된다.
- **편향이 낮다**: 모델이 훈련 데이터를 잘 학습하고, 훈련 데이터의 관계를 제대로 파악할 수 있는 경우이다. 이때는 훈련 데이터에서 예측이 잘 맞고, **모델이 훈련 데이터를 잘 표현할 수 있다.**

<br>

### 2. **분산(variance)**

- **분산이 높다**: 모델이 훈련 데이터에 너무 맞춰져서 **과적합(overfitting)**된 경우이다. 훈련 데이터에서는 성능이 좋지만, **새로운 테스트 데이터에서는 성능이 떨어지는 현상**이 발생한다다. 이는 모델이 훈련 데이터의 작은 변화나 잡음까지 학습해버려서 테스트 데이터에 일반화되지 않기 때문이다.
- **분산이 낮다**: 모델이 훈련 데이터에 과도하게 맞추지 않고, **일관된 성능을 유지하는 경우이다**. 이때는 훈련 데이터와 테스트 데이터에서 성능 차이가 적다.

<br>

### K-폴드 교차 검증에서 K의 값을 선택할 때 고려해야 할 점은 무엇인가요?

K-폴드 교차 검증은 주어진 데이터를 K개의 부분으로 나누어 그 중 하나를 테스트 데이터로, 나머지를 훈련 데이터로 사용해 모델을 여러 번 평가하는 방법이다. 여기서 K의 값은 얼마나 많은 번 데이터를 나눠서 실험할지를 결정하는 숫자다. K가 너무 작으면 모델의 평가가 신뢰성 없을 수 있고, K가 너무 크면 계산이 느려진다.

<br>

K의 값은 마치 시험에서 문제의 수와 같다고 볼 수 있다. 너무 적으면 결과가 신뢰할 수 없고, 너무 많으면 시간을 많이 소모한다. 적당한 수의 문제를 푸는 것이 효율적이다.

모델의 성능을 보다 정확하게 평가하기 위해 필요하다. 이를 통해 데이터가 부족할 때 과적합(overfitting)을 방지하고, 모델이 다양한 데이터에 어떻게 반응하는지 확인할 수 있다.
