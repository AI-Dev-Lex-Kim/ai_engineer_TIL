# [CV 논문 리뷰]Squeeze-and-Excitation Networks

논문 링크: https://arxiv.org/pdf/1709.01507

> 이번 논문은 지난 attention is all you need 보다 수월하게 읽을 수 있었다.
> SE 구조가 복잡한 구조도 아니고 작은 MLP이다 보니 이해하는데 어렵지 않았다.

## <mark>**Abstract**</mark>

컨볼루션 신경망(CNN)은 이미지를 처리할때, 각 레이어마다 작은 영역( local receptive fields)만을 보면서 공간적 특징과 채널별 정보를 섞어서 더 좋은 특징을 만든다.

즉, CNN은 기본적으로 “공간정보”도 보고 “채널정보”도 본다.

여기서 공간 정보란, 피처맵에서 각 영역들의 픽셀 위치나 영역의 정보를 말한다.

그동안 <mark>**대부분의 연구는 이 중에서 공간 정보를 더 잘 인코딩하는 방법에 집중**</mark>해왔다. 예를 들어 “어떤 픽셀 주변에 어떤 패턴이 있는지”를 더 잘 포착하는 것이 목표였다.

<br>

그런데 <mark>**이 논문에서는 “채널 간의 관계”에 집중**</mark>한다.

예를 들어, 어떤 필터가 “색깔 정보”를 잡고, 어떤 필터가 “윤곽선”을 잡는다면, 그 둘 사이의 중요도, 상호의존성 같은 것을 더 명확하게 모델링하는 것이다.

이를 위해 논문 저자들은 새로운 구조인 “Squeeze-and-Excitation”(SE)”을 제안한다.

<br>

이 SE 블록은 간단히 말해서 다음을 의미한다.

1. <mark>**Squeeze 단계: 채널마다 전역적인(전체 공간을 다본) 정보를 하나로 압축해서, 그 채널이 전체 그림에서 얼마나 중요한지 요약한다.**</mark>
2. <mark>**Excitation 단계: 요약한 정보를 사용해서 “이 채널은 더 강조하고, 저 채널은 덜 강조해라” 처럼 채널별 가중치를 학습한다.**</mark>

즉, 입력 이미지마다 <mark>**“현재 상황에 맞게 어떤 채널을 더 강조해야 하는가”를 SE블록이 판단해서 네트워크에 다시 흘려주는 구조**</mark>이다.

그래서 SE는 <mark>**각 채널의 중요도를 동적으로 조정하는 일종의 채널 어텐션 역활**</mark>을 한다.

<br>

그리고 <mark>**이 작은 블록을 기존 CNN 사이에 쌓아 넣으면 “SENet”이라는 아키텍처**</mark>가 된다.

이 논문에서 실제로 실험 해보았더니 이 SENet은 여러 데이터셋에서 일반화도 잘되고, 기존 모델보다 성능이 확실히 좋아졌고한다.

<mark>**심지어 계산량이 거의 증가하지 않는데도 성능 향상이 꽤 크다는 점이다.**</mark>

<br>

## Introduction

![SE block](https://velog.velcdn.com/images/lexkim/post/a5285b42-105d-45be-9ea1-b240d42a8cad/image.png)

컨볼루션 신경망(CNN)은 분류, 객체 탐지, 분할처럼 이미지 관련 작업이면 매우 잘 맞는 모델로 많이 입증되었다.

CNN 안의 컨볼류션 레이어에서는 여러개의 필터가 존재한다.

CNN의 필터는 채널안의 한 지점만 보는게 아니라 그 주변 픽셀들과의 관계를 함께보며 패턴을 인식한다.

그래서 공간적(모양, 패턴)과 채널별(RGB 조합, 깊은 층의 의미있는 특징)을 동시에 섞어 더 풍부한 정보를 만든다.

<br>

<mark>**컴퓨터 비전 연구의 큰 목표는 결국 더 뛰어난 표현(representation)을 만드는 것**</mark>이다.

<mark>**이미지에서 정말 중요한 부분만 뽑으며, 불필요한 정보는 버릴수 있다는 뜻이다.**</mark>

이것이 잘되면 같은 이미지라도 더 쉽게 분류하거나 분석하여 성능이 향상된다.

<br>

최근 CNN의 표현을 더 강하게 만들기 위해서 단순히 주변 패턴을 보는것에서 끝나지 않고, “<mark>**이 특징이 저 특징과 공간적으로 어떤 관계를 맺고 있는가?**</mark>”를 네트워크가 더 잘 이해하도록 학습 메커니즘을 연구했다.

<br>

그 중에서도 <mark>**Inception 아키텍처 계열이 가장 유명**</mark>했다.

inception의 핵심 아이디어는 <mark>**여러 크기의 필터를 동시에 적용해 다양한 스케일 정보를 한번에 보는것**</mark>이다.

<mark>**작은 필터는 로컬 디테일을 보며, 큰 필터는 더 넓은 문맥을 담을 수 있다.**</mark>

이렇게 <mark>**multi-scale 정보를 한 블록에서 동시에 처리**</mark>하면 성능이 좋아진다는것을 확인되었다.

<br>

추가적인 연구로 이미지 내의 <mark>**특정 영역에 주목하도록 만드는 공간적 어텐션(spatial attention)**</mark>을 도입하는 방법도 있다.

즉, <mark>**이미지 전체를 균일하게 보지 않고, 중요한 부분에 더 집중**</mark>하는 것이다.

<br>

연구자들은 지금까지 CNN 구조를 개선할때 주로 <mark>**공간 정보(어디에 무엇이 있는가**</mark>에 집중해왔다.

그런데 이 논문은 완전히 다른 방향을 본다.

바로 <mark>**채널 간의 관계에 집중**</mark>한다.

<br>

이미지 특징맵은 수십~수백개의 채널로 이루어져있다.

각 채널은 서로 다른 종류의 특징을 담고 있다.(색감, 경계선, 패턴 등)

<mark>**그런데 어떤 채널이 지금 중요한지, 어떤 채널은 덜 중요한지 판단하는 메커니즘이 없었다.**</mark>

<br>

논문에서는 바로 이 문제를 해결하기 위해 SE(Squeeze-and-Excitation)블록 이라는 새 구조를 만든다.

SE 블록의 목표는 단 하나이다.

<br>

이미지 마다 어떤 채널이 중요한지 자동으로 판단해서

<mark>**중요한 채널은 더 강조하고, 덜 중요한 채널은 약하게 해준다.**</mark>

이걸 논문에서는 <mark>**특징 재조정(feature recalibration)**</mark>이라고 부른다.

<br>

SE 블록은 두 단계로 이루어진다.

1. 스퀴즈(Squeeze) 단계

   특징 맵 U를 받아서 H x W공간 전체를 평균낸다.

   <br>

   <mark>**왜 평균을 낼까?**</mark>

   <mark>**그 채널이 전체 이미지에서 얼마나 활성화되는지 요약한 값만 보면 그 채널이 지금 중요한지 대략 감을 잡을 수 있기 떄문이다.**</mark>

   <br>

   예를들어

   - 채널5가 전체적으로 높은값 → 이미지에서 자주 활성화됨 → 중요한 채널일 확률 높음
   - 채널 13이 전체적으로 낮은 값 → 거의 활성화 되지 않음 → 덜 중요할 채널일 가능성 높음

   <br>

   채널 1 → 하나의 숫자 s1

   채널2 → 하나의 숫자 s2

   …

   채널 C → 하나의 숫자 sC

   <br>

   이 숫자들 전체를 모아서 만든 길이가 C 짜리 벡터가 채널 디스크립터(channel descriptor)이다.

   이 디스크립터는 <mark>**각 채널이 전체 이미지에서 얼마나 중요한가를 요약한 벡터**</mark>이다.

   <br>

2. 익사이트(excitation) 단계

   이제 채널 디스크립터 s = [s1, s2, …, sC]가 만들어졌다.

   하지만 이대로 쓰면 단순히 채널 평균값에 따라 가중치가 결정되어서 모델이 상황에 따라 유연한 판단을 할 수 없다.

   <br>

   그래서 이 디스크립터 s를 작은 신경만(MLP)에 넣는다.

   이것이 익사이트 단계이다.

   <br>

   입력된 s를 바탕으로 <mark>**각 채널을 얼마나 키울지 혹은 줄일지 결정하는 가중치 벡터를 만든다.**</mark>

   가중치 벡터 w = [w1, w2, …, wC]

   - w5 = 1.7 → 채널 5를 1.7배 키워라(중요하다는 뜻)
   - w13 = 0.2 → 채널 13을 0.2배 줄여라(덜 중요하다는 뜻)

   <br>

   <mark>**이 가중치를 원래 특징 맵 U에 곱하면,**</mark>

   <mark>**각 채널이 상황에 맞게 강조, 억제된 새로운 특징이 만들어진다.**</mark>

   이게 SE 블록의 출력이며 다음 레이어로 전달된다.

<br>

이 SE 블록은 단순하기 때문에 어디든 삽입할 수 있다.

원래 CNN의 블록에 SE 블록을 붙여준다.(drop-in replacement)

그러면 전체 구조는 거의 변하지 않는데 성능만 오른다.

<br>

<mark>**어떤식으로 CNN 블록에 SE 블록을 붙일까?**</mark>

1. 기존 구조

   [Conv → BN → ReLU → Conv → BN → Conv → BN]

2. SE를 붙인 구조

   [기존 CNN 블록]

   → SE Block

   → 출력

<br>

단순히 끼워 넣기만 해도 되기때문에, 이렇게 복잡한 아키텍처 설계없이도 성능을 안정적으로 끌어올릴수 있다.

<br>

## Related Work

### Deeper architectures - 깊은 아키텍처

딥러닝 기반의 컴퓨터 비전연구는 오랫동안 <mark>**어떻게 하면 더 깊고 강력한 네트워크를 안정적으로 학습할수 있을까?**</mark> 라는 문제를 중심으로 발전해왔다.

이러한 배경에서 VGGNet과 Inception 모델에서 <mark>**네트워크의 깊이를 늘리는것(레이어를 추가함)만으로도 표현력이 크게 개선**</mark>될 수 있음을 보여주었다.

<mark>**Batch Normalization(BN)은 깊은 네트워크에서 학습이 불안정해지는 문제를 해결**</mark>해주며 최적화 과정을 한층 더 매끄럽게 만들어주었다.

<mark>**Hightwaynet work**</mark>는 이러한 <mark>**스킵 경로에 게이트를 추가해서 정보가 지나가는 양을 조절**</mark>하는 기능을 더했다.

이후에도 네트워크 레이어들을 연결하는 다양한 방법이 제시되면서 <mark>**딥러이 모델의 학습 안정성과 표현력은 꾸준히 강화**</mark> 되어왔다.

<br>

이 과정에서 <mark>**채널간 상관관계를 다루는 기존방식은 대부분 채널을 단순히 조합하는 연산에 가까웠다.**</mark>

이런 기법들은 모델의 계산량을 줄이는데 초점을 맞추었다.

<mark>**채널 관계는 로컬한 함수들의 조합으로 충분하다는 암묵적인 가정위에서 발전해왔었다.**</mark>

<br>

하지만 SE 블록의 관점은 완전히 다르다.

채널 간 관계는 단순히 로컬 정보를 조합해 얻을 수 있는것이 아니라,

<mark>**이미지 전체(global context)를 반영해야하며, 상황에 따라 동적으로 변화하는 비선형 관계라는 것이다.**</mark>

따라서 이러한 <mark>**채널 의존성을 직접 학습할 수 있도록 해주는 메커니즘**</mark>을 네트워크 안에 넣는 것이 표현력 향상에 더 효과적이라고 주장한다.

바로 이점이 SE 블록의 핵심 아이디어이다.

<br>

### Algorithmic Architecture Search - 알고리즘적 아키텍처 탐색

---

딥러닝 모델 구조를 설계하는 과정에서 원래 연구자가 직접 레이어수, 커널 크기 등을 하나하나 정해야하는 매우 복잡한 작업이였다.

<mark>**모델 구조 자체를 알고리즘이 자동으로 찾아내는 아키텍처 탐색(NAS)을 찾았다.**</mark>

NAS는 다양한 탐색 전략이 있는 거대한 연구분야로 성장했다.

이러한 탐색 과정에서 <mark>**SE 블록이 매우 유용한 구성단위로 활용**</mark>될 수 있다.

SE 블록은 작고 가벼우며, 어떤 CNN 구조에도 쉽게 삽입할 수 있다.

<br>

### Attention and gating mechanisms — 어텐션과 게이트 메커니즘

---

어텐션은 가장 중요한 부분에 더 많은 계산 자원을 집중시키는 방법이다.

공간적 어텐션(어디가 중요한지)과 채널 어텐션(어떤 종류의 특징이 중요한지)을 결합하는 방식도 시도 되었다.

하지만 이런 구조는 계산량이 꽤 크고 설계도 복잡하다.

<br>

하지만 SE 블록은 훨씬 단순하고 가볍다.

<mark>**SE 블록은 오직 채널 간 관계(channel-wise relationships)를 학습하는데 집중하는 매우 가벼운 게이팅(gating) 매커니즘이다.**</mark>

<br>

## Squeeze-And-Excitation blocks

![SE block](https://velog.velcdn.com/images/lexkim/post/45121d8f-2988-49b1-99d5-965dae40a05f/image.png)

<mark>**convolution 연산 수식**</mark>

$$
u_c = v_c ∗ X = \sum_{s=1}^{C`} v^s_c ∗ x^s
$$

X = [x1, x2, …, xC] → 입력 채널들을 나타냄

$v_c$ = [v1, v2, …, vC] → C번째 출력 채널을 만드는 필터의 각 채널별 커널

<br>

출력 $u_c$의 각 픽셀은 모든 입력 채널과 해당 필터 채널을 convolution 한 후 합친 값이다.

<mark>**즉, 출력 한 채널을 만들때, 입력 모든 채널을 섞어서 특징을 만든다는 뜻이다.**</mark>

<mark>**예시**</mark>

- 입력 X: 채널 2개, x1, x2
- 필터 vc: 채널 2개, v1, v2
- uc = v1 ∗ x1 + v2 ∗ x2
- 이렇게 해서 하나의 출력 채널 uc가 완성

<br>

convolution은 각 출력 채널을 만들때 모든 입력 채널을 사용한다.

<mark>**채널 간 관계가 일부 반영되지만, 이건 암묵적(local)적이다.**</mark>

예를 들어, <mark>**어떤 채널이 중요한지 명시적으로 알려주지 않는다.**</mark>

대부분의 관계는 필터가 감지한 지역적 패턴에 의존한다.

<br>

<mark>**SE 블록은 채널 간 관계를 명시적으로 반영해준다.**</mark>

<mark>**이렇게 하면 네트워크가 중요한 feature를 더 잘 반영할 수 있다.**</mark>

어떤 채널은 강조하고, 덜 중요한 채널은 줄인다는 조정이 가능해진다.

- <mark>**Squeeze**</mark>: 각 채널의 정보를 평균이나 요약으로 뽑아 <mark>**전역 정보**</mark>를 얻음
- <mark>**Excitation**</mark>: 그 전역 정보를 이용해 <mark>**각 채널의 중요도**</mark>를 계산 → 가중치 생성

<br>

### Squeeze: Global information embedding

convlution 연산으로 나온 출력 U는 지역적인(local) 정보만을 사용한다.

각 필터는 작은 영역(receptive filed)만 보고 특징을 추출한다.

<mark>**즉, 한 픽셀이나 작은 패치 주변 정보만 반영하고 전체 이미지 맥락(global context)는 반영하지 못한다.**</mark>

<br>

SE 블록에서는 채널 간 관계(chaneel dependency)를 활용하려고 한다.

예를 들어 어떤 채널이 전체 이미지에서 중요한지 판단하고 싶을 때, 작은 영역 정보만으로는 부족하다.

<br>

그래서 <mark>**전역 정보를 한 채널로 요약하**</mark>는 작업을 한다.

이것을 위해서 <mark>**global average pooling(GAP)을 사용**</mark>한다.

<mark>**각 채널의 H x W 크기 데이터를 하나의 값으로 평균한다.**</mark>

이렇게 하면 각 채널이 전체 이미지에서 가진 <mark>**대표 값(channel descriptor) 하나로 압축**</mark>된다.

<br>

<mark>**Squeeze 수식**</mark>

$$
z_c = F_{sq}(u_c) = \frac{1}{(H × W)} \sum_{i=1}^{H} \sum_{j=1}^{W} u_c(i, j)
$$

- $z_c$ → c 번째 채널을 대표하는 값
- $u_c(i, j)$ → c번째 채널의 (i, j) 위치 값
- H x W → 영역 전체를 평균 → 하나의 숫자로 요약

<br>

<mark>**H x W 크기의 2D feature map을 1개의 대표 숫자로 만든다는 것이다.**</mark>

<mark>**모든 채널에 대해 반복해서 채널의 개수 만큼의 크기 벡터가 생성된다.**</mark>

<br>

예시

- 입력 채널 3개, 각 채널이 4×4 행렬:

```python
uc = [[1,2,3,4],
      [5,6,7,8],
      [9,10,11,12],
      [13,14,15,16]]
```

- $z_c$ = (1+2+...+16) / 16 = 8.5
- 이렇게 채널별로 하나씩 계산 → z = [$z_{c1}$, $z_{c2}$, $z_{c3}$]

<br>

정리하자면,

U 는 작은 영역 정보로 이루어진 feature map들의 모임이다.

<mark>**각 채널의 평균을 뽑으면 채널이 전체이미지에서 어떤 정보를 담고 있는지 대표값이 된다.**</mark>

<mark>**이 값들을 SE 블록의 Excitation 단계에서 활용해서 채널 중요도를 계산한다.**</mark>

<br>

### Excitation: Adaptive Recalibration

---

Squeeze 단계에서 각 채널의 전역 정보를 요약한 z 벡터를 얻었다.

이제 이 정보를 바탕으로 <mark>**각 채널의 중요도(channel weight)를 계산하는 단계가 바로 Excitation 이다.**</mark>

<br>

<mark>**즉, Squeeze는 정보를 모으는 단계, Excitation은 그 정보를 이용해 채널별 가중치를 만드는 단계라고 생각하면 된다.**</mark>

<br>

Excitation는 두가지 조건을 만족해야한다.

1. 유연성(flexibility)
   - 채널 간 상호작용(interaction)을 비선형적으로 학습할 수 있어야한다.
   - 단순 선형 연산으로는 복잡한 채널 관계를 잡아내기 어렵다.
2. 비상호 배타적(non-mutually-exclusive)
   - 여러 채널을 동시에 강조할수 있어야한다.
   - 한 채널만 강조하고 나머지는 억제하는 on-hot 방식이 아니어야한다.

<br>

<mark>**Excitation 수식**</mark>

$$
s = F_{ex}(z, W) = σ(g(z,W)) = σ(W_2 δ(W_1 z))
$$

- z → Squeeze 단계에서 나온 채널 요약 벡터
- $W_1$, $W_2$ → 학습 가능한 가중치(fully-connected-layer)
- $\delta$ → ReLU 활성화 함수
- $\sigma$ → sigmoid 활성화 함수
- s → 각 채널별 가중치(0~1 사이 값)

<br>

아키텍처 흐름

z → FC layer($W_1$) → ReLU → FC layer($W_2$) → sigmoid

<br>

<mark>**왜 이런 수식을 사용했는지?**</mark>

1. 두 개의 FC 레이어 = W1, W2

   채널 간의 비선형 상호작용을 모델링을 목적으로 한다.

   z 벡터는 각 채널이 전체 이미지에서 어느정도 중요한지 나타내지만,

   <mark>**채널끼리 서로 영향을 줄 수 있는 관계를 반영하기 위해 FC layer → ReLU → FC layer 구조를 사용했다.**</mark>

   <br>

   첫번째 FC(W1)는 <mark>**차원 축소 목적**</mark>이다.

   Bottlenect 구조

   - 파라미터 수 감소로 모델 복잡도를 줄인다.
   - 일반화를 향상시켜 과적합을 방지하다.

   <br>

   두번째 FC(W2)는 원래 차원으로 복원해준다.

   - <mark>**각 채널별 가중치를 다시 원래 크기로 맞춘다.**</mark>

   <br>

2. ReLU 할성화 함수

   <mark>**비선형성을 추가해서 채널 간 복잡한 상호작용을 학습할 수 있게해준다.**</mark>

   ReLU를 사용해서 음수 정보는 제거하고 양수 신호만을 강조한다.

   <br>

3. Sigmoid

   최종 출력 s는 각 채널별 가중치이다.

   Sigmoid는 0~1 사이의 값으로 제한해서 얼마나 강조하고 억제할지 정규화한다.

   <mark>**한 채널만 강조하고 다른 채널을 억제하는 것이 아니라, 여러 채널이 동시에 강조하고 억제할 수 있게한다.**</mark>

   <br>

<mark>**Bottlenect 구조**</mark>

<mark>**모델 복잡도를 줄이고 일반화**</mark>를 돕기 위해 두 개의 fully-connected layer 사이에 차원 축소(reduction)와 복원 구조를 사용한다.

<br>

<mark>**최종 출력 계산(Recalibaration)**</mark>

각 채널의 feature map $u_c$에 SE 블록을 거친 $s_c$를 곱한다.

$$
\widetilde{x}_c = F_{scale}(u_c, s_c) = s_c * u_c
$$

$$
\widetilde{X} = [\widetilde{x}_1, \widetilde{x}_2, ..., \widetilde{x}_C]
$$

<br>

- $\widetilde{X}$ → 최종 출력 feature map
- 여기서 중요한 점은 $s_c$ 값이 클수록 해당 채널이 강조되고, 작으면 억제된다.

<br>

정리하자면,

<mark>**Excitation 단계는 입력에 따라 동적으로(channel-wise self-attention) feature map을 조정하는 단계이다.**</mark>

<br>
### Instantiations

<mark>**SE 블록은 유연하게 기존 네트워크에 넣을 수 있다.**</mark>

지금까지의 설명에서는 convolution 블록 이후, SE Block을 넣었다.

예를 들어서 VGGnet에 SE 블록 삽입 → SE-VGGNet

<br>

<mark>**SE 블록은 convolution 외에 다른 변환에도 적용이 가능하다는 점이다.**</mark>

Inception 모듈 후에 SE Block을 넣으면 SE-Inception 네트워크가 된다.

Residual 모듈에서도 identity branch와 합치기 전에 SE Block을 적용하면 SE-ResNet 구조가 된다.

<br>

<mark>**SE Block은 최근에 나온 다양한 아키텍처에도 적용이 가능하다.**</mark>

- ResNeXt, Inception-ResNet, MobileNet, ShuffleNet 등

<br>

SE Block 삽입하는 방식은 여러가지가 가능하다.

<mark>**따라서 네트워크 성능이 어디에 SE를 넣느냐에 따라 달라질수있다.**</mark>

이것을 확인하려면 성능 비교 실험(ablation study)를 수행해야한다.

여러 설계 전략을 비교하고 어떤 위치, 어떤 방식이 최적인지 평가해야한다.

<br>

## Model and Computational Complexity

SE 블록을 실제 네트워크에 사용하려면 성능 향상과 계산 비용 증가라는 균형이 중요하다.

논문에서는 ResNet-50에 SE Block을 추가해서 측정을 해봤더느 0.26%라는 계산 비용 증가가 매우 작았다.

계산량은 아주 작게 증가했지만, 성능은 ResNet-101에 가까운 성능을 보여주었다고 한다.

<br>

## Conclusion

SE 블록은 기존 CNN이 잘 처리하지 못하던 채널 간 의존성을 해결하기 위해 만들어진 모듈이다.

CNN은 공간적 특징을 추출하는 데는 강하지만, 각 채널이 서로 어떤 의미적 관계를 가지는지 반영하는 데는 한계가 있었다.

<mark>**SE 블록은 이 문제를 해결하기 위해 채널별 정보를 먼저 전역적으로 압축하고(squeeze), 그 정보를 바탕으로 각 채널의 중요도를 다시 계산(excitation)하여 특징 맵에 곱해 준다.**</mark>

이렇게 하면 모델이 중요한 채널은 더 강조하고 덜 중요한 채널은 약하게 사용하게 되어, 표현력이 향상된다.

실험 결과로 SE Block은 기존 네트워크 구조에 간단하게 붙여 사용할 수 있으며, 계산량 증가도 작은데 성능 향상이 되었다.

<br>
