[Text Generation and Prompting OpenAI Docs](https://platform.openai.com/docs/guides/text?api-mode=responses&lang=python&prompt-example=prompt#page-top)

---

# OpenAI 프롬프트 엔지니어링(Prompt Template)

모델이 텍스트를 생성하도록 프롬프트하는 방법을 학습한다.

간단한 프롬프트에서 텍스트를 생성한다.

```python
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-4.1",
    input="Write a one-sentence bedtime story about a unicorn."
)

print(response.output_text)
```

```python
[
    {
        "id": "msg_67b73f697ba4819183a15cc17d011509",
        "type": "message",
        "role": "assistant",
        "content": [
            {
                "type": "output_text",
                "text": "달의 부드러운 빛 아래, 유니콘 루나는 반짝이는 별똥별 들판을 가로질러 춤을 추었고, 잠든 모든 아이들을 위해 꿈의 흔적을 남겼다.",
                "annotations": []
            }
        ]
    }
]
```

<br>

## 프롬프트 엔지니어링

**프롬프트 엔지니어링**은 모델이 요구 사항을 일관되게 충족하는 콘텐츠를 생성하도록 **효과적인 Instruction을 작성**하는 프로세스이다.

모델에서 생성된 콘텐츠는 비결정적이기 때문에 원하는 형식으로 콘텐츠를 생성할 **프롬프트를 구축하는 것은 예술과 과학의 조합**이다.

그러나 모델에서 일관되게 좋은 결과를 얻기 위해 적용할 수 있는 여러 기술과 모범 사례가 있다.

<br>

일부 프롬프트 엔지니어링 기술은 메시지 역할 사용과 같이 모든 모델에서 작동한다.

그러나 **다른 모델 유형은 최상의 결과를 생성하기 위해 다르게 프롬프트**해야 할 수 있다.

동일한 모델 스냅샷조차도 다른 결과를 생성할 수 있다.

<br>

따라서 더 복잡한 애플리케이션을 구축할 때 다음을 강력히 권장한다.

- 일관된 동작을 보장하기 위해 **특정 [모델 스냅샷](https://www.google.com/search?q=/docs/models)(예: `gpt-4.1-2025-04-14`)에 프로덕션 애플리케이션을 고정**한다.
- **프롬프트의 성능을 모니터링**하고, 프롬프트를 반복하거나 모델 버전을 변경 및 업그레이드할 때 프롬프트의 동작을 측정할 [평가](https://www.google.com/search?q=/docs/guides/evals)를 구축한다.

<br>

## 메시지 역할 및 Instruction 따르기

`instructions` 매개변수는 모델이 응답을 생성하는 동안 어떻게 동작해야 하는지에 대한 높은 수준의 Instruction을 제공하며, 톤, 목표 및 올바른 응답의 예시를 포함한다.

이 방식으로 제공된 모든 Instruction은 `input` 매개변수의 프롬프트보다 우선한다.

Instruction으로 텍스트를 생성한다.

```python
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-4.1",
    instructions="해적처럼 말해.",
    input="JavaScript에서 세미콜론은 선택 사항인가요?",
)

print(response.output_text)
```

위 예시는 `input` 배열에서 다음 입력 메시지를 사용하는 것과 거의 동일하다.

다른 역할을 사용하여 메시지로 텍스트를 생성한다.

```python
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-4.1",
    input=[
        {
            "role": "developer",
            "content": "해적처럼 말해."
        },
        {
            "role": "user",
            "content": "JavaScript에서 세미콜론은 선택 사항인가요?"
        }
    ]
)

print(response.output_text)
```

<br>

`instructions` 매개변수는 현재 응답 생성 요청에만 적용된다는 점에 유의한다.

`previous_response_id` 매개변수로 대화 상태를 관리하는 경우, 이전 턴에 사용된 `instructions`는 컨텍스트에 존재하지 않는다.

| **`developer`** | **`user`** | **`assistant`** |
| --------------- | ---------- | --------------- |

| 1. `developer` 메시지는 애플리케이션 개발자가 제공하는 Instruction이다.

2. 개발자 메시지는 사용자 메시지보다 우선순위를 가진다. 개발자가 애플리케이션 동작을 제어하기 위함이다.

3. 사용자 입력에 앞서 개발자의 의도를 명확히 전달하는 수단이다. 예를들어 특정 기능의 사용 제한이나 필수 입력 사항 등을 명시할 수 있다.

4. `developer` 메시지는 함수 정의와 같이 시스템의 규칙과 비즈니스 로직을 제공한다. | 1. 사용자 메시지는 최종 사용자가 제공하는 Instruction이다.

2.사용자 메시지는 개발자 메시지보다 우선순위가 낮다. 이는 사용자가 애플리케이션에 원하는 작업을 지시할 때 사용된다.

3. 개발자가 설정한 기본적인 틀 안에서 사용자의 상호작용을 가능하게 한다. 예를 들어, 검색어 입력, 특정 버튼 클릭 등이 사용자 메시지에 해당한다.

4.`developer` 메시지 Instruction이 적용되는 입력 및 구성을 제공한다. | 1. 모델이 생성하는 메시지는 **어시스턴트 역할**을 가진다. 이는 모델이 사용자 또는 개발자의 지시에 따라 **응답을 제공**함을 의미한다.

2. 어시스턴트 메시지는 **정보 제공, 질문 답변, 코드 생성** 등 다양한 형태를 띤다.

3. 시스템 대화에서 모델의 **출력 결과**를 나타내는 중요한 부분이다. 예를 들어, 사용자의 질문에 대한 답변이나 요청된 작업의 결과를 포함한다. |

## 재사용 가능한 프롬프트

OpenAI 대시보드에서 코드에 프롬프트의 내용을 지정하는 대신 API 요청에 사용할 수 있는 **재사용 가능한 [프롬프트](https://www.google.com/search?q=/chat/edit)를 개발**할 수 있다.

이렇게 하면 프롬프트를 더 쉽게 구축하고 평가할 수 있으며, **통합 코드를 변경하지 않고도 개선된 버전의 프롬프트를 배포**할 수 있다.

작동 방식은 다음과 같다.

1. 대시보드에서 `{{customer_name}}`과 같은 플레이스홀더로 **재사용 가능한 프롬프트를 생성한다**.
2. `prompt` 매개변수를 사용하여 **API 요청에서 프롬프트를 사용한다**. 프롬프트 매개변수 객체에는 구성할 수 있는 세 가지 속성이 있다.
   - `id` — 대시보드에서 찾을 수 있는 **프롬프트의 고유 ID**
   - `version` — 프롬프트의 특정 버전 (대시보드에 지정된 "현재" 버전으로 기본 설정됨)
   - `variables` — **프롬프트의 변수에 대체할 값의 맵**이다. 대체 값은 문자열이거나 `input_image` 또는 `input_file`과 같은 다른 응답 입력 메시지 유형일 수 있다.

<br>

프롬프트 템플릿으로 텍스트를 생성한다.

```python
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-4.1",
    prompt={
        "id": "pmpt_abc123",
        "version": "2",
        "variables": {
            "customer_name": "Jane Doe",
            "product": "40oz juice box"
        }
    }
)

print(response.output_text)
```

<br>

파일 인풋이 있는 프롬프트 템플릿

```python
import openai, pathlib

client = openai.OpenAI()

# 변수에서 참조할 PDF를 업로드한다.
file = client.files.create(
    file=open("draconomicon.pdf", "rb"),
    purpose="user_data",
)

response = client.responses.create(
    model="gpt-4.1",
    prompt={
        "id": "pmpt_abc123",
        "variables": {
            "topic": "Dragons",
            "reference_pdf": {
                "type": "input_file",
                "file_id": file.id,
            },
        },
    },
)

print(response.output_text)
```

<br>

## 마크다운 및 XML을 사용한 메시지 형식 지정

`developer` 및 `user` 메시지를 작성할 때 **마크다운 서식과 XML 태그를 조합하여 모델이 프롬프트 및 컨텍스트 데이터의 논리적 경계를 이해**하도록 도울 수 있다.

<br>

`developer`, `user` 메시지를 작성할때 **마크다운이나 XML 사용하면 장점**이 있다.

1. 마크다운 헤더와 목록은 프롬프트의 개별 섹션을 표시하고 **모델에 계층 구조를 전달하는 데 유용**할 수 있다.
2. **개발 중에 프롬프트를 더 읽기 쉽게 만들 수 있다.**
3. XML 태그는 **하나의 콘텐츠가 시작되고 끝나는 위치를 구분**하는 데 도움이 될 수 있다.

<br>

develop 메시지는 Identity, Instructions, Examples, Context 네 가지 섹션으로 구성된다.

- **Identity:** 모델이 수행해야 할 작업의 **전체적인 방향과 스타일을 설정하는 역할**을 한다.(정체성 부여)
  - 예시: "너는 정보를 추출하여 JSON으로 만드는 전문가야"라고 역할을 부여
- **Instructions:** 모델이 따라야 할 명확하고 **구체적인 규칙을 순서대로 제공**한다.
  - 예시: 'JSON으로만 답할 것', '정보가 없으면 null로 처리할 것' 등 **세부 규칙을 통해 결과물의 일관성과 정확성을 높인다.**
- **Examples:** 모델에게 실제 입력과 그에 따른 바람직한 출력의 쌍을 보여준다.
  모델은 이 **예시를 통해 복잡한 지시사항을 직관적으로 학습**하고, **결과물의 포맷을 정확하게 모방**하게 된다.
  특히 두 번째 예시에서 회사명이 `null`로 처리된 것을 보여줌으로써, **정보가 누락되었을 때 어떻게 대처해야 하는지를 명확히 학습**시킨다.
- **Context:** **실제 처리해야 할 데이터**(`user_input`)를 제공한다.
  이 구조는 모델에게 "앞에서 학습한 모든 것을 바탕으로, 이제 이 새로운 데이터를 처리해라"는 명확한 작업 흐름을 만들어 준다.
- document:

<br>

```python
structured_prompt = """
<prompt>
    <identity>
        너는 사용자로부터 입력된 자연어 텍스트에서 주요 정보를 추출하여 JSON 객체로 구조화하는 전문 AI 어시스턴트이다.
        너의 유일한 임무는 정보를 정확하게 추출하고 지정된 형식으로 변환하는 것이다.
    </identity>

    <instructions>
        1. 텍스트에서 사용자의 '이름', '이메일 주소', '회사명'을 추출해야 한다.
        2. 응답은 반드시 JSON 형식이어야 하며, 다른 어떤 설명이나 추가 텍스트도 포함해서는 안 된다.
        3. 만약 특정 정보(예: 회사명)를 찾을 수 없는 경우, 해당 값은 'null'로 처리해야 한다.
        4. JSON 객체의 키는 반드시 'name', 'email', 'company'를 사용해야 한다.
    </instructions>

    <examples>
        <example>
            <input>안녕하세요. 저는 네이버의 홍길동입니다. 제 이메일은 gildong@naver.com 입니다.</input>
            <output>
                {
                    "name": "홍길동",
                    "email": "gildong@naver.com",
                    "company": "네이버"
                }
            </output>
        </example>
        <example>
            <input>저는 이순신입니다. 이메일 주소는 lee@example.com 입니다.</input>
            <output>
                {
                    "name": "이순신",
                    "email": "lee@example.com",
                    "company": null
                }
            </output>
        </example>
    </examples>

    <context>
        <document>
            이제 아래 제공되는 새로운 사용자 입력을 처리할 차례이다.
            모든 지시사항과 예시를 철저히 따라야 한다.
        </document>
        <user_input>
            {new_user_text}
        </user_input>
    </context>
</prompt>
"""

# 사용자 입력
user_text_to_process = "만나서 반갑습니다. 제 이름은 유관순이고, 카카오에서 일하고 있습니다. 연락처는 ryu@kakao.com 입니다."

# 프롬프트 템플릿의 '{new_user_text}' 부분을 실제 사용자 입력으로 교체
final_prompt = structured_prompt.format(new_user_text=user_text_to_process)
```

<br>

### `<instructions>` vs `<document>`

LLM은 텍스트를 처음부터 끝까지 순서대로 처리한다.

프롬프트의 길이가 길어질수록 앞부분의 내용을 잊어버리거나 중요도를 낮게 판단하는 경향이 있다.

이 때문에 프롬프트의 뒷부분에 나오는 정보가 모델의 최종 행동에 더 강한 영향을 미치는 경향이 있다.

이를 ‘최신성 편향(Recency Bias)'이라고 한다.

`<document>` 태그는 이러한 현상을 방지하고, 모델의 주의를 다시 **핵심 목표로 집중시키는 앵커(Anchor)** 역할을 수행하여 최종 응답의 정확성과 신뢰도를 높여준다.

<br>

`<instructions>`와 여러 `<examples>`를 처리하며 길어진 프롬프트의 가장 마지막, 즉 실제 작업을 수행할 `<user_input>` 직전에 위치하여, 모델이 따라야 할 지시사항의 **우선순위**를 다시 최상위로 끌어올린다.

긴 맥락(context)을 처리한 후 분산될 수 있는 모델을 핵심 작업으로 다시 집중시킨다.

- **`<instructions>`**
  프롬프트 전체에 적용되는 **'정적 규칙(Static Rule)**'을 정의한다. \***\*모델이 따라야 할 명확하고 **구체적인 규칙을 순서대로 제공\*\*한다.
- **`<document>`**
  **학습된 규칙을 바로 다음 입력값에 적용하라고 지시**하는 **'동적 명령(Dynamic Command)'**을 정의한다.
  '이제, 배운 것을 실행하라'는 절차적인 명령에 해당합니다.

<br>

### 프롬프트 캐싱으로 비용 및 지연 시간 절약

메시지를 구성할 때 API 요청에서 반복적으로 사용할 것으로 예상되는 콘텐츠가 있다.

프롬프트의 시작 부분에 Responses에 대한 JSON request body에 전달하는 첫 번째 API 매개변수 중 하나로 유지해야 한다.

이렇게 하면 [프롬프트 캐싱](https://platform.openai.com/docs/guides/prompt-caching)을 통해 비용 및 지연 시간 절약을 극대화할 수 있다.

<br>

## Few-shot learning

Few-shot learning은 모델을 **직접 파인튜닝하지 않고, 프롬프트에 소수의 입출력 예시를 포함**시켜 새로운 작업을 지시하는 기법이다.

모델은 주어진 예시들로부터 **암묵적으로 패턴을 파악**하고, 이를 새로운 요청에 적용하여 응답한다.

<br>

좋은 결과를 얻기 위해서는, **다양한 종류의 입력과 그에 상응하는 원하는 출력 예시**를 보여주는 것이 중요하다.

```python
few_shot_prompt_template = """
# Identity
당신은 상품 리뷰의 감성을 '긍정', '부정', '중립' 세 가지로 분류하는 전문 어시스턴트입니다.

# Instructions

* 응답은 반드시 '긍정', '부정', '중립' 중 하나의 단어로만 출력해야 합니다.
* 어떠한 부가 설명이나 서식도 포함해서는 안 됩니다.

# Examples
<product_review id="example-1">
		이 헤드폰 정말 인생템입니다. 음질이 뛰어나고 디자인도 마음에 쏙 들어요. 강력 추천합니다!
</product_review>
<assistant_response id="example-1">긍정</assistant_response>

<product_review id="example-2">
		배터리는 그냥저냥 쓸만한데, 이어패드 마감이 좀 저렴한 느낌이네요. 가성비는 그닥...
</product_review>
<assistant_response id="example-2">중립</assistant_response>

<product_review id="example-3">
		고객센터 응대가 정말 최악이네요. 다시는 여기서 구매 안 합니다.
</product_review>
<assistant_response id="example-3">부정</assistant_response>
"""

new_review_text = "This is the best purchase I've made all year, highly recommended!"

# 최종 프롬프트를 조립
final_prompt = (
    few_shot_prompt_template + # 1단계에서 정의한 템플릿
    f'<product_review id="example-4">{new_review_text}</product_review>\n' + # 2단계의 새로운 리뷰
    '<assistant_response id="example-4">' # 모델이 이어서 답변을 생성하도록 유도
)
```

### 동작 원리 심층 설명

1. **패턴 학습 (Pattern Recognition)**: AI 모델은 `Instructions`의 지시사항을 읽기도 하지만, 더 중요하게는 **`<examples>`에 나열된 입출력 쌍의 패턴을 학습**한다. `<product_review>` 태그 안의 텍스트가 주어지면, `<assistant_response>` 태그 안에는 'Positive', 'Negative', 'Neutral' 중 하나가 온다는 **구조를 스스로 파악**한다. 이것이 Few-shot learning의 핵심 원리이다.
2. **문맥 내 학습 (In-Context Learning)**: 이 학습은 모델의 기본 파라미터를 영구적으로 변경하는 `파인튜닝`과 근본적으로 다르다. **학습은 오직 이 프롬프트가 처리되는 '문맥 안에서만' 일시적으로 일어난다**. 프롬프트에 예시를 제공함으로써, 모델을 올바른 방향으로 유도하는 것이다.
3. **응답 형식 강제**: 프롬프트의 마지막 부분을 보면, `<assistant_response id="example-4">` 까지만 제공하고 끝난다. 이것은 **모델에게 "이제 네가 이어서 이 태그를 완성해" 라고 강력하게 신호를 보내는 역할**을 한다. 모델은 이전 예시들에서 이 태그 뒤에는 항상 한 단어의 감성 레이블이 왔다는 것을 학습했기 때문에, 지시에 따라 'Positive'라는 단어만 생성할 확률이 매우 높아진다.

<br>

개발자는 몇 가지 대표적인 예시만으로 모델의 **행동을 정교하게 제어**하고, 원하는 **특정 작업을 안정적으로 수행**하도록 만들 수 있다.

<br>

## 관련 컨텍스트 정보 포함(Include relevant context information)

컨텍스트를 추가하는 주된 이유는 모델이 학습하지 않은 **비공개 데이터를 제공**하거나, **신뢰할 수 있는 특정 자료에만 기반하여 응답**하도록 제한하기 위함이다.

이렇게 **외부 데이터를 검색**하여 프롬프트에 추가하는 기법을 **'검색 증강 생성(Retrieval-Augmented Generation, RAG)'**이라고 부른다.

**모델이 한 번에 처리할 수 있는 데이터의 양에는 한계**가 있으며, 이를 **'컨텍스트 창(Context Window)'**이라고 한다.

컨텍스트 창의 크기는 '토큰(Token)' 단위로 측정되며, 모델마다 처리할 수 있는 최대 토큰 수가 다르므로 모델 문서를 확인해야 한다.

<br>

## GPT-4.1 모델 프롬프트

**GPT-4.1 모델은 명확하고 구체적인 지시사항에 매우 잘 반응**하므로, 프롬프트에 **작업에 필요한 논리와 데이터를 명시적으로 제공**하는 것이 중요하다.

**에이전트**처럼 자율적으로 작동하게 하려면 **'지속성(Persistence)', '도구 호출(Tool Calling)', '계획(Planning)'에 대한 지시를 프롬프트에 포함**시키는 것이 권장된다.

1백만 토큰의 긴 컨텍스트 창을 효과적으로 사용하기 위해, **중요한 지시사항은 프롬프트의 맨 위와 맨 아래 양쪽에 배치하는 것이 최적의 성능**을 이끌어낸다.

**단계별 사고(Chain of Thought)를 유도하여 문제 해결 능력을 높일** 수 있으며, 모델이 지시를 매우 문자 그대로 따르므로 구체적인 작업 흐름과 규칙을 명시해야 한다.

**도구 사용은 API의 `tools` 필드를 사용하는 것이 가장 좋으며**, 코드 변경 사항을 나타내는 'diff' 생성 성능이 크게 향상되었다.

<br>

### GPT-4.1 프롬프트 모범 사례

### 시스템 프롬프트 알림

GPT-4.1의 에이전트 기능을 가장 잘 활용하려면 모든 에이전트 프롬프트에 지속성, 도구 호출 및 계획을 위한 세 가지 주요 유형의 알림을 포함하는 것이 좋다.

전체적으로 이러한 세 가지 Instruction은 모델의 동작을 챗봇과 같은 동작에서 훨씬 더 "열정적인" 에이전트로 전환하여 상호 작용을 자율적이고 독립적으로 진행하도록 유도한다. 다음은 몇 가지 예시이다.

```python
# GPT-4.1 모델을 '에이전트'처럼 작동
# 지속성, 도구 호출, 계획 수립 세 가지 핵심 지시사항
agentic_system_prompt = """
# 정체성
당신은 사용자의 요청을 해결하기 위해 파일 시스템과 상호작용하는 AI 에이전트이다.

# 지시사항

## 지속성 (PERSISTENCE)
당신은 에이전트이다. 사용자의 요청이 완전히 해결될 때까지 작업을 계속 수행해야 한다.
문제가 해결되었다고 확신할 때만 당신의 턴을 종료하고 사용자에게 제어권을 넘겨라.

## 도구 호출 (TOOL CALLING)
사용자의 요청과 관련된 파일 내용이나 코드베이스 구조에 대해 확신이 없다면,
추측하거나 답을 지어내지 말고, 반드시 도구를 사용하여 파일을 읽고 관련 정보를 수집하라.

## 계획 수립 (PLANNING)
함수를 호출하기 전에는 반드시 상세하게 계획을 세워야 하며, 이전 함수 호출의 결과를 바탕으로 깊이 성찰해야 한다.
단순히 함수 호출만 반복해서는 안 된다. 이는 문제 해결 능력과 통찰력 있는 사고를 저해할 수 있다.
"""
# 사용자 질문
user_query = "config.json 파일에 명시된 프로젝트 버전이 어떻게 돼?"

# 최종 답변을 생성
final_answer = "확인 결과, config.json 파일에 명시된 프로젝트 버전은 '1.2.5' 입니다."
```

### 동작 원리 및 핵심 요약

1. **추측 방지 및 사실 기반 응답**: 가장 중요한 규칙은 `도구 호출`이다. 이 지시가 없었다면, 구형 모델은 "파일에 접근할 수 없어 알 수 없습니다"라고 답하거나, 최악의 경우 "버전은 1.0.0일 것입니다"와 같이 정보를 지어냈을 것이다. 하지만 이 **규칙 때문에 에이전트는 모르는 정보에 대해 반드시 `read_file` 도구를 사용하게 되어 사실에 기반한 정확한 답변을 생성**한다.
2. **체계적인 문제 해결**: `계획 수립` 규칙은 에이전트가 무작정 코드를 실행하거나 도구를 호출하는 대신, **'목표 확인 -> 현재 상태 분석 -> 계획 수립 -> 실행 -> 결과 성찰' 이라는 체계적인 흐름을 따르도록 강제**한다. 이는 복잡한 문제 해결에 있어 매우 중요한 과정이다.
3. **능동적인 목표 완수**: `지속성` 규칙은 에이전트가 **한 번의 실패(예: 파일 경로가 틀렸을 경우)에 작업을 포기하지 않고**, "혹시 파일 이름이 다른가요?"라고 사용자에게 되묻거나 다른 방법을 시도하는 등, **문제가 완전히 해결될 때까지 작업**을 이어간다.

<br>

이처럼 GPT-4.1에 최적화된 프롬프트는 단순히 '무엇을 하라'고 지시하는 것을 넘어, '어떻게 생각하고 행동해야 하는지'에 대한 **가이드라인을 제공함으로써 모델의 성능을 극대화하고, 더 신뢰할 수 있으며 유능한 AI 에이전트를 구축**할 수 있게 한다.

<br>

### 프롬프트 구성

특히 긴 컨텍스트 사용 시 Instruction 및 **컨텍스트 배치는 성능에 상당한 영향**을 미칠 수 있다.

긴 컨텍스트를 처리할 때, 모델이 프롬프트의 중간 부분을 잊어버리는 경향이 있다.

가장 중요한 규칙이나 목표는 프롬프트의 시작과 끝에 한 번씩 더 강조하여 모델이 항상 기억하도록 만든다.

OpenAI는 **사용자 쿼리를 포함한 중요한 Instruction을 프롬프트의 맨 위와 맨 아래 모두에 배치**하는 것이 최적이라는 것을 발견했다.

이는 맨 위에만 배치하는 것보다 모델에서 약간 더 나은 성능을 이끌어냈고, **맨 아래에만 배치하는 것보다 훨씬 더 나은 성능**을 이끌어냈다.

<br>

GPT-4.1은 추론 모델이 아니지만, 모델이 **문제를 쉬운 부분으로 분해하고 단계별로 생각하도록 프롬프트하는 것은 효과적인 방법**이 될 수 있다.

모델은 에이전트 추론 및 실제 문제 해결에서 잘 수행하도록 훈련되었으므로 잘 수행하기 위해 많은 프롬프트가 필요하지 않다.

프롬프트 끝에 이 기본적인 사고의 사슬 Instruction으로 시작하는 것이 좋다.

```python
먼저, 쿼리에 답하기 위해 어떤 문서가 필요한지 단계별로 신중하게 생각한다.
그런 다음 각 문서의 제목과 ID를 출력한다.
그런 다음 ID를 목록으로 형식화한다.
```

거기에서 특정 예시 및 평가에서 실패를 감사하고, 더 명시적인 Instruction으로 체계적인 계획 및 추론 오류를 해결하여 CoT 프롬프트를 개선해야 한다.

더 독단적인 추론 전략을 보여주는 프롬프트 예시는 요리책을 참조한다.

<br>

## Instruction following

GPT-4.1 모델은 지시를 매우 문자 그대로 따르기 때문에, 프롬프트를 얼마나 정교하고 명확하게 작성하는지가 결과물의 품질을 결정하는 핵심 요소이다.

여기서는 '실패하는 프롬프트'를 '성공하는 프롬프트'로 개선하는 과정을 통해 올바른 접근법을 보여준다.

<br>

**개신이 필요한 프롬프트**

```python
initial_flawed_prompt = """
# Instruction
- 고객에게 공감하는 태도를 보여라.
- 배송 지연 문제에 대해 사과하고 10% 할인 쿠폰을 발급하라.
- "배송이 늦어져 정말 죄송합니다." 라는 문구를 사용하라.

# 사용자 입력:
{user_input}
"""
```

<br>

**개선된 프롬프트**

```python
revised_prompt = """
# Response Rules
- 당신의 역할은 고객의 불만을 응대하고 해결하는 전문 상담원이다.
- 항상 공손하고 공감하는 어조를 유지해야 한다.

## 공감 표현 예시
- 다음은 고객에게 공감을 표현할 때 참고할 수 있는 문구들이다. 이 문구들을 그대로 사용하지 말고, 상황에 맞게 자연스럽게 변형하여 사용하라.
  - "오래 기다리셨을 텐데, 정말 죄송합니다."
  - "많이 답답하셨을 것 같습니다. 불편을 드려 죄송합니다."
  - "주문하신 상품을 제때 받지 못해 속상하셨겠어요."

## 처리 절차
- 다음 단계를 순서대로 따라야 한다.
  1. 먼저, 고객의 감정에 공감하며 사과한다.
  2. 고객의 주문번호를 확인하고, 배송 지연이 맞는지 내부 시스템을 통해 조회한다. (도구 호출 시뮬레이션)
  3. 만약 주문번호 조회가 실패하면, 정중하게 주문번호를 다시 확인해달라고 요청한다.
  4. 배송 지연이 확인되면, 사과의 의미로 10% 할인 쿠폰을 발급한다고 안내한다.
  5. 추가로 궁금한 점이 있는지 확인하며 대화를 마무리한다.

# 사용자 입력:
{user_input}
"""

```

<br>

### 권장 워크플로우

다음은 프롬프트에서 Instruction을 개발하고 디버깅하기 위한 권장 워크플로우이다.

- `Response Rules` or `Instruction`: 구체적으로 작성한 응답 규칙 또는 지시를 작성한다.
- `Sample Pharses`: 더 구체적인 동작을 변경하려면 모델의 디테일한 예제를 만들어준다.
- `Work flow`: AI가 수행해야 할 작업에 **명확한 순서가 있다면**, 번호 목록을 사용해 절차를 알려준다.
- **문제 해결 및 디버깅**: GPT-4.1은 지시를 문자 그대로 따르므로, 지침이 충돌하면 응답이 안좋아질 수 있다.
  특히 GPT-4.1은 **프롬프트의 뒷부분에 있는 지시를 더 중요하게 여기는 경향**이 있습니다.
  충돌하는 Instruction이 있는 경우 **GPT-4.1은 프롬프트 끝에 더 가까운 Instruction을 따르는 경향**이 있다.
- **구체적인 예시 추가**: 규칙을 글로만 설명하는 것보다, **실제 대화 예시를 보여주는 것이 훨씬 효과적**이다.
  모델이 지시사항을 더 빠르고 정확하게 이해하도록 돕는 가장 강력한 방법 중 하나이다.
  단, **예시에서 보여준 행동은 반드시 규칙에도 명시되어 있어야 일관성이 유지**됩니다.
- **강조 및 인센티브:** 필수는 아니지만, 특정 지침을 **특별히 강조하고 싶을 때** 시도해볼 수 있는 방법이다.
  GPT-4.1은 이미 지시를 잘 따르므로 보통은 필요 없다. 하지만 여러 번 수정해도 AI가 특정 규칙을 계속 어긴다면, 최후의 수단으로 사용하여 해당 지침의 중요도를 높이는 효과를 기대해 볼 수 있다.

<br>

## Prompt Debugging

GPT-4.1의 일반적인 실패 모드는 프롬프트 지시사항이 **너무 엄격하거나, 모호하거나, 예외 상황을 고려하지 않았을 때** 주로 발생한다.

문제들은 **AI가 지시를 너무 문자 그대로 따르려는 성향** 때문에 생기며, 몇 가지 간단한 원칙으로 대부분 해결할 수 있다.

<br>

### **지나치게 엄격한 규칙의 함정**

"**무조건** ~해야 한다" 또는 "**반드시** ~하라"와 같은 절대적인 규칙은 **AI가 융통성 없이 행동하게 만들어 오히려 역효과**를 낼 수 있다.

'반드시 호출'이라는 명령을 지키기 위해, AI는 있지도 않은 주문번호를 지어내거나(`hallucination`) 빈 값으로 도구를 호출하는 등 **비논리적인 행동**을 할 수 있다.

<br>

**해결 방법**

AI에게 '안전장치' 또는 '대체 경로'를 만들어준다.

"만약 도구를 호출할 정보가 충분하지 않다면, **사용자에게 필요한 정보를 요청해.**" 라는 예외 처리 지침을 추가한다.

이렇게 하면 AI는 무리하게 도구를 호출하는 대신, "주문 조회를 원하시면 주문번호를 알려주시겠어요?"와 같이 더 지능적인 행동을 할 수 있다.

<br>

**반복되는 응답**

AI에게 응답 예시를 주면, **창의성 없이 그 문구를 그대로 복사해서 사용하는 경향**이 있다.

프롬프트에 "고객에게 사과할 때는 '불편을 드려 죄송합니다.'라고 말해." 라고 지시하면, **AI는 모든 사과 상황에서 기계적으로 해당 문장만 반복**하게 된다.

이는 고객에게 진심이 담겨있지 않은 **로봇 같은 인상**을 준다.

<br>

**해결 방법**

참고는 하지만 변형해서 사용하라고 명확하게 지시해야 한다.

예를 들어,

> "다음은 사과할 때 참고할 수 있는 표현이야: '불편을 드려 죄송합니다', '기다리시게 해서 죄송한 마음입니다'.

<br>

“이 표현들을 **그대로 쓰지 말고, 상황에 맞게 자연스럽게 바꾸어서 응답해**." 와 같이 지시하는 것이다.

이렇게 하면 AI는 **주어진 예시를 통해 더 다채롭고 진정성 있는 응답을 생성**한다.

<br>

### **불필요하게 과도한 설명**

결과값만 간단히 받으면 되는데, AI가 너무 의욕이 넘쳐 부가적인 설명이나 불필요한 서식을 덧붙이는 경우가 있다.

<br>

리뷰가 긍정인지 부정인지만 알고 싶어서 "이 리뷰 감성을 분석해줘." 라고 요청했다.

AI가

> "이 리뷰는 **긍정적**입니다. 왜냐하면 '최고예요'라는 표현은 강한 만족감을 나타내기 때문입니다. 따라서 사용자는 이 제품을 매우 좋아하는 것으로 보입니다."

같이 **장황한 설명**을 덧붙일 수 있다. 이런 부가 정보는 자동화된 시스템을 망가뜨릴 수 있다.

<br>

**해결 방법**

원하는 **출력 형식을 매우 구체적이고 명시적으로 지정**해야 한다.

> "리뷰 감성을 분석해서 **'긍정', '부정', '중립' 중 단 하나의 단어로만 응답해.** 그 외에 어떤 설명이나 문장도 절대 덧붙이지 마."

같이 결과물의 형태를 명확히 제한하는 것이다. 이렇게 하면 AI는 정확히 당신이 원하는 형태의 결과물만 반환한다.

<br>

## 추가 구현

[Prompt Caching](https://platform.openai.com/docs/guides/prompt-caching)

[GPT-4.1 Prompting Guide](https://cookbook.openai.com/examples/gpt4-1_prompting_guide)
